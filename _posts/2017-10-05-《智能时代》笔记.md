---
layout: "post"
---


今天奋发图强，是因为，我明天决定：不干活！

哈哈


来吧，今天要讲的第二个问题就是，大数据！

以下内容截取自《智能时代》 

吴军博士迷妹表示，这本书依然很好看！

# 机械思维

1. 世界变化的规律是确定的，这一点从托勒密到牛顿大家都认可。 
2. 因为有确定性做保障，因此规律不仅是可以被认识的，而且可以用简单的公式或语言描述清楚。
3. 这些规律应该是放之四海而皆准的，可以应用到各种未知领域指导实践，这种认识是在牛顿之后才有的。 


机械思维的重要特征： 所有问题有一个通用的解决方法。 
机械思维作为一种准则指导人们的行为，其核心思想可以概括成确定性（或者可预知性）和因果关系


# 大数据思维

在无法确定因果关系时，数据为我们提供了解决问题的新方法，数据中所包含的信息可以帮助我们消除不确定性，而数据之间的相关性在某种程度上可以取代原来的因果关系，帮助我们得到我们想知道的答案。 

大数据三大特征： 

* 数据量大
* 多维度
* 完备性


大数据的本质就是利用信息消除不确定新。 


如果我们能找到确定性（或可预测性）和因果关系，可以使用机械思维。 但今天我们面临复杂的情况， 不确定性是社会的常态，在无法确定因果关系时，数据为我们提供了解决问题的新方法，数据中包含的信息可以帮助我们消除不确定性，而数据之间的相关性在某种程度上可以取代原来的因果关系，帮助我们得到答案。 


从大数据中找到普遍规律，就能找到异常情况。


# 信息论
信息论完全建立在不确定性基础上，而想要消除这种不确定性，就要引入信息。 至于要引入多少信息，则要看系统中的不确定性有多大。这种思路成为信息时代做事情的根本方法。

利用信息来消除不确定性的问题。 

## 互信息 （ Mutual Information） 

互信息 （ Mutual Information）可解释为什么信息的现骨干性可以帮助我们解决很多问题。 

我们获得信息和要研究的事物需要有“关联性”才能帮助我们消除不确定性，搞清楚我们想要研究的问题。 

信息论里用互信息这个概念，实现了相关性的量化度量。

互信息大，则表示两个信息之间有很强的关联系。 

## 香农第一定律 （香农信源编码定律） 

假定有一个信息源，里面有N种信息，现在我们需要对着N种信息一一进行编码，比如我们用0011来表示第一种信息。10000111表示第二种...
用这些编码当然不能重复，否则我们就无法根据编码来断定是哪一种信息了。虽然编码可以有很多种方法，但是有的方法效率高，有的低，或者说用很长的编码才能表示一个信息。
香弄第一定律讲的是，对于信源发出的所有信息设计一种编码，那么编码的平均长度一定大于该信源的信息熵，但同时香农还指出，一定存在一种编码方式，使得编码的平均长度无限接近于它的信息熵。 

## 香农第二定律

信息的传宝速率不可能超过信道的容量。 


### 最大熵原理

当我们要对未知的事件寻找一个概率模型时，这个模型应当满足我们所有已经看到的数据，但是对未知的情况不要做任何主观假设。 

最大熵原理已经不同于“大胆假设，小心求证”的方法论，因为它要求不引入主观假设。 
不做主观假设的前提是取得了足够多的数据，否则最大熵的模型只能给出一些平均值而已，而不能对任何细节进行描述和预测。 

熵：信息论和不确定性的代名词


### 交叉熵

它可以反映两个信息源之间的一致性，或者两种概率模型之间的一致性。 
当两个数据完全一致时，他们的交叉熵等于0。 
当他们相差很大时， 交叉熵也很大。 
所有采用数据驱动的方法，建立模型所使用的数据和使用模型的数据之间需要有一致性。也就是代表性 
交叉熵是对这种代表性或者一致性的一种精确的量化度量 。




******* 

最后，推荐一本书： 《编码》

计算机入门读物，一扫我计算机是怎么做成的困扰。 

额，也没有那么有趣其实，估计这书要是放在初中的时候给我看，我肯定是不会看的。 




